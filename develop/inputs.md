# Pipeline


## Inputs


### Required inputs
<p name="Pipeline.annotationGTF">
        <b>Pipeline.annotationGTF</b><br />
        <i>File &mdash; Default: None</i><br />
        GTF annotation containing genes, transcripts, and edges.
</p>
<p name="Pipeline.annotationVersion">
        <b>Pipeline.annotationVersion</b><br />
        <i>String &mdash; Default: None</i><br />
        Name of supplied annotation (will be used to label data).
</p>
<p name="Pipeline.dockerImagesFile">
        <b>Pipeline.dockerImagesFile</b><br />
        <i>File &mdash; Default: None</i><br />
        The docker image used for this workflow. Changing this may result in errors which the developers may choose not to address.
</p>
<p name="Pipeline.executeSampleWorkflow.presetOption">
        <b>Pipeline.executeSampleWorkflow.presetOption</b><br />
        <i>String &mdash; Default: None</i><br />
        This option applies multiple options at the same time in minimap2.
</p>
<p name="Pipeline.genomeBuild">
        <b>Pipeline.genomeBuild</b><br />
        <i>String &mdash; Default: None</i><br />
        Genome build (i.e. hg38) to use.
</p>
<p name="Pipeline.organismName">
        <b>Pipeline.organismName</b><br />
        <i>String &mdash; Default: None</i><br />
        The name of the organism from which the data was collected.
</p>
<p name="Pipeline.pipelineRunName">
        <b>Pipeline.pipelineRunName</b><br />
        <i>String &mdash; Default: None</i><br />
        A name describing the pipeline run.
</p>
<p name="Pipeline.referenceGenome">
        <b>Pipeline.referenceGenome</b><br />
        <i>File &mdash; Default: None</i><br />
        Reference genome fasta file.
</p>
<p name="Pipeline.sampleConfigFile">
        <b>Pipeline.sampleConfigFile</b><br />
        <i>File &mdash; Default: None</i><br />
        Samplesheet describing input fasta/fastq files.
</p>
<p name="Pipeline.sequencingPlatform">
        <b>Pipeline.sequencingPlatform</b><br />
        <i>String &mdash; Default: None</i><br />
        The sequencing machine used to generate the data.
</p>

### Other common inputs
<p name="Pipeline.createDatabase.minimumLength">
        <b>Pipeline.createDatabase.minimumLength</b><br />
        <i>Int &mdash; Default: 300</i><br />
        Minimum required transcript length.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.bufferSize">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.bufferSize</b><br />
        <i>Int &mdash; Default: 100</i><br />
        Number of lines to output to file at once by each thread during run.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.correctIndels">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.correctIndels</b><br />
        <i>Boolean &mdash; Default: true</i><br />
        Set this to make TranscriptClean correct indels.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.correctMismatches">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.correctMismatches</b><br />
        <i>Boolean &mdash; Default: true</i><br />
        Set this to make TranscriptClean correct mismatches.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.correctSJs">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.correctSJs</b><br />
        <i>Boolean &mdash; Default: true</i><br />
        Set this to make TranscriptClean correct splice junctions.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.deleteTmp">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.deleteTmp</b><br />
        <i>Boolean &mdash; Default: true</i><br />
        The temporary directory generated by TranscriptClean will be removed.
</p>
<p name="Pipeline.executeSampleWorkflow.howToFindGTAG">
        <b>Pipeline.executeSampleWorkflow.howToFindGTAG</b><br />
        <i>String? &mdash; Default: None</i><br />
        How to find GT-AG. f:transcript strand, b:both strands, n:don't match GT-AG.
</p>
<p name="Pipeline.executeSampleWorkflow.variantVCF">
        <b>Pipeline.executeSampleWorkflow.variantVCF</b><br />
        <i>File? &mdash; Default: None</i><br />
        VCF formatted file of variants.
</p>
<p name="Pipeline.executeTalon.minimumCoverage">
        <b>Pipeline.executeTalon.minimumCoverage</b><br />
        <i>Float &mdash; Default: 0.9</i><br />
        Minimum alignment coverage in order to use a SAM entry.
</p>
<p name="Pipeline.executeTalon.minimumIdentity">
        <b>Pipeline.executeTalon.minimumIdentity</b><br />
        <i>Int &mdash; Default: 0</i><br />
        Minimum alignment identity in order to use a SAM entry.
</p>
<p name="Pipeline.novelIDprefix">
        <b>Pipeline.novelIDprefix</b><br />
        <i>String &mdash; Default: "TALON"</i><br />
        Prefix for naming novel discoveries in eventual TALON runs.
</p>
<p name="Pipeline.outputDirectory">
        <b>Pipeline.outputDirectory</b><br />
        <i>String &mdash; Default: "."</i><br />
        The directory to which the outputs will be written.
</p>
<p name="Pipeline.runTranscriptClean">
        <b>Pipeline.runTranscriptClean</b><br />
        <i>Boolean &mdash; Default: true</i><br />
        Option to run TranscriptClean after Minimap2 alignment.
</p>

### Advanced inputs
<details>
<summary> Show/Hide </summary>
<p name="Pipeline.convertDockerImagesFile.dockerImage">
        <b>Pipeline.convertDockerImagesFile.dockerImage</b><br />
        <i>String &mdash; Default: "quay.io/biocontainers/biowdl-input-converter:0.2.1--py_0"</i><br />
        The docker image used for this task. Changing this may result in errors which the developers may choose not to address.
</p>
<p name="Pipeline.convertSampleConfig.checkFileMd5sums">
        <b>Pipeline.convertSampleConfig.checkFileMd5sums</b><br />
        <i>Boolean &mdash; Default: false</i><br />
        Whether or not the MD5 sums of the files mentioned in the samplesheet should be checked.
</p>
<p name="Pipeline.convertSampleConfig.old">
        <b>Pipeline.convertSampleConfig.old</b><br />
        <i>Boolean &mdash; Default: false</i><br />
        Whether or not the old samplesheet format should be used.
</p>
<p name="Pipeline.convertSampleConfig.skipFileCheck">
        <b>Pipeline.convertSampleConfig.skipFileCheck</b><br />
        <i>Boolean &mdash; Default: true</i><br />
        Whether or not the existance of the files mentioned in the samplesheet should be checked.
</p>
<p name="Pipeline.createAbundanceFile.datasetsFile">
        <b>Pipeline.createAbundanceFile.datasetsFile</b><br />
        <i>File? &mdash; Default: None</i><br />
        A file indicating which datasets should be included.
</p>
<p name="Pipeline.createAbundanceFile.memory">
        <b>Pipeline.createAbundanceFile.memory</b><br />
        <i>String &mdash; Default: "4G"</i><br />
        The amount of memory available to the job.
</p>
<p name="Pipeline.createAbundanceFile.whitelistFile">
        <b>Pipeline.createAbundanceFile.whitelistFile</b><br />
        <i>File? &mdash; Default: None</i><br />
        Whitelist file of transcripts to include in the output.
</p>
<p name="Pipeline.createDatabase.cutoff3p">
        <b>Pipeline.createDatabase.cutoff3p</b><br />
        <i>Int &mdash; Default: 300</i><br />
        Maximum allowable distance (bp) at the 3' end during annotation.
</p>
<p name="Pipeline.createDatabase.cutoff5p">
        <b>Pipeline.createDatabase.cutoff5p</b><br />
        <i>Int &mdash; Default: 500</i><br />
        Maximum allowable distance (bp) at the 5' end during annotation.
</p>
<p name="Pipeline.createDatabase.memory">
        <b>Pipeline.createDatabase.memory</b><br />
        <i>String &mdash; Default: "10G"</i><br />
        The amount of memory available to the job.
</p>
<p name="Pipeline.createSJsfile.memory">
        <b>Pipeline.createSJsfile.memory</b><br />
        <i>String &mdash; Default: "8G"</i><br />
        The amount of memory available to the job.
</p>
<p name="Pipeline.createSJsfile.minIntronSize">
        <b>Pipeline.createSJsfile.minIntronSize</b><br />
        <i>Int &mdash; Default: 21</i><br />
        Minimum size of intron to consider a junction.
</p>
<p name="Pipeline.createSummaryFile.datasetGroupsCSV">
        <b>Pipeline.createSummaryFile.datasetGroupsCSV</b><br />
        <i>File? &mdash; Default: None</i><br />
        File of comma-delimited dataset groups to process together.
</p>
<p name="Pipeline.createSummaryFile.memory">
        <b>Pipeline.createSummaryFile.memory</b><br />
        <i>String &mdash; Default: "4G"</i><br />
        The amount of memory available to the job.
</p>
<p name="Pipeline.createSummaryFile.setVerbose">
        <b>Pipeline.createSummaryFile.setVerbose</b><br />
        <i>Boolean &mdash; Default: false</i><br />
        Print out the counts in terminal.
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.cores">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.cores</b><br />
        <i>Int &mdash; Default: 4</i><br />
        The number of cores to be used.
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.kmerSize">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.kmerSize</b><br />
        <i>Int &mdash; Default: 15</i><br />
        K-mer size (no larger than 28).
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.matchingScore">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.matchingScore</b><br />
        <i>Int? &mdash; Default: None</i><br />
        Matching score.
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.maxFragmentLength">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.maxFragmentLength</b><br />
        <i>Int? &mdash; Default: None</i><br />
        Max fragment length (effective with -xsr or in the fragment mode).
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.maxIntronLength">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.maxIntronLength</b><br />
        <i>Int? &mdash; Default: None</i><br />
        Max intron length (effective with -xsplice; changing -r).
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.memory">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.memory</b><br />
        <i>String &mdash; Default: "30G"</i><br />
        The amount of memory available to the job.
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.mismatchPenalty">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.mismatchPenalty</b><br />
        <i>Int? &mdash; Default: None</i><br />
        Mismatch penalty.
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.retainMaxSecondaryAlignments">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.retainMaxSecondaryAlignments</b><br />
        <i>Int? &mdash; Default: None</i><br />
        Retain at most INT secondary alignments.
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.secondaryAlignment">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.secondaryAlignment</b><br />
        <i>Boolean &mdash; Default: false</i><br />
        Whether to output secondary alignments.
</p>
<p name="Pipeline.executeSampleWorkflow.executeMinimap2.skipSelfAndDualMappings">
        <b>Pipeline.executeSampleWorkflow.executeMinimap2.skipSelfAndDualMappings</b><br />
        <i>Boolean &mdash; Default: false</i><br />
        Skip self and dual mappings (for the all-vs-all mode).
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.canonOnly">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.canonOnly</b><br />
        <i>Boolean &mdash; Default: false</i><br />
        Only output canonical transcripts and transcript containing annotated noncanonical junctions.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.cores">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.cores</b><br />
        <i>Int &mdash; Default: 1</i><br />
        The number of cores to be used.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.dryRun">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.dryRun</b><br />
        <i>Boolean &mdash; Default: false</i><br />
        TranscriptClean will read in the data but don't do any correction.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.maxLenIndel">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.maxLenIndel</b><br />
        <i>Int &mdash; Default: 5</i><br />
        Maximum size indel to correct.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.maxSJoffset">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.maxSJoffset</b><br />
        <i>Int &mdash; Default: 5</i><br />
        Maximum distance from annotated splice junction to correct.
</p>
<p name="Pipeline.executeSampleWorkflow.executeTranscriptClean.memory">
        <b>Pipeline.executeSampleWorkflow.executeTranscriptClean.memory</b><br />
        <i>String &mdash; Default: "25G"</i><br />
        The amount of memory available to the job.
</p>
<p name="Pipeline.executeTalon.cores">
        <b>Pipeline.executeTalon.cores</b><br />
        <i>Int &mdash; Default: 4</i><br />
        The number of cores to be used.
</p>
<p name="Pipeline.executeTalon.memory">
        <b>Pipeline.executeTalon.memory</b><br />
        <i>String &mdash; Default: "25G"</i><br />
        The amount of memory available to the job.
</p>
<p name="Pipeline.spliceJunctionsFile">
        <b>Pipeline.spliceJunctionsFile</b><br />
        <i>File? &mdash; Default: None</i><br />
        A pre-generated splice junction annotation file.
</p>
<p name="Pipeline.talonDatabase">
        <b>Pipeline.talonDatabase</b><br />
        <i>File? &mdash; Default: None</i><br />
        A pre-generated TALON database file.
</p>
</details>








<hr />

> Generated using WDL AID (0.1.1)
